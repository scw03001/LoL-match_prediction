{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code generates more diverse augmenteed images than augment_1 (used for multimodal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.transforms import RandomRotation, ColorJitter, RandomHorizontalFlip, RandomCrop\n",
    "from torchvision.transforms import RandomAffine\n",
    "\n",
    "from torch.optim.lr_scheduler import CyclicLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "\n",
    "def mask_image(image, rect_coords):\n",
    "    # Create a black mask\n",
    "    mask = Image.new('L', image.size, 0)  \n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    \n",
    "    # Draw white rectangles for the specified areas\n",
    "    for rect in rect_coords:\n",
    "        x1, y1 = min(rect[0], rect[2]), min(rect[1], rect[3])\n",
    "        x2, y2 = max(rect[0], rect[2]), max(rect[1], rect[3])\n",
    "        draw.rectangle([x1, y1, x2, y2], fill=255)\n",
    "\n",
    "    # Apply the mask to the image\n",
    "    masked_image = Image.new('RGB', image.size, (0, 0, 0))  \n",
    "    masked_image.paste(image, mask=mask)  \n",
    "    return masked_image\n",
    "\n",
    "def process_and_save_frames(input_dir, output_dir, rect_coords):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # for each match folder\n",
    "    for match_id in os.listdir(input_dir):\n",
    "        match_folder = os.path.join(input_dir, match_id)\n",
    "        if not os.path.isdir(match_folder):\n",
    "            continue\n",
    "        \n",
    "        output_match_folder = os.path.join(output_dir, match_id)\n",
    "        os.makedirs(output_match_folder, exist_ok=True)\n",
    "\n",
    "        # apply mask to each frame\n",
    "        for frame in os.listdir(match_folder):\n",
    "            if not frame.endswith('.jpg'):\n",
    "                continue\n",
    "\n",
    "            frame_path = os.path.join(match_folder, frame)\n",
    "            image = Image.open(frame_path).convert(\"RGB\")\n",
    "            masked_image = mask_image(image, rect_coords)\n",
    "\n",
    "            # save\n",
    "            output_path = os.path.join(output_match_folder, frame)\n",
    "            masked_image.save(output_path)\n",
    "\n",
    "    print(f\"Masked images saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked images saved to ./data/masked_frames\n"
     ]
    }
   ],
   "source": [
    "input_dir = './data/frames'\n",
    "output_dir = './data/masked_frames'\n",
    "rect_coords = [\n",
    "    (675, 10, 1242, 85),\n",
    "    (1755, 5, 1916, 72),\n",
    "    (292, 95, 2, 5),\n",
    "    (1630, 793, 1915, 1074),\n",
    "    (597, 846, 1335, 1077),\n",
    "    (1828, 126, 1918, 648),\n",
    "    (83, 132, 1, 655),\n",
    "]\n",
    "\n",
    "process_and_save_frames(input_dir, output_dir, rect_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_multiple(image, num_augmentations=10):\n",
    "    # apply augmentation\n",
    "    augmentations = transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomCrop(size=(image.size[1] - 50, image.size[0] - 50)),\n",
    "        transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1))\n",
    "    ])\n",
    "    \n",
    "    augmented_images = [augmentations(image) for _ in range(num_augmentations)]\n",
    "    return augmented_images\n",
    "\n",
    "\n",
    "\n",
    "def augment_train_data(train_dir, num_augmentations=10):\n",
    "    # apply augmentation only for the training data\n",
    "    matches = os.listdir(train_dir)\n",
    "\n",
    "    for match_id in tqdm(matches, desc=\"Processing Matches\", unit=\"match\"):\n",
    "        match_folder = os.path.join(train_dir, match_id)\n",
    "        if not os.path.isdir(match_folder):\n",
    "            continue\n",
    "\n",
    "        frames = [f for f in os.listdir(match_folder) if f.endswith('.jpg')]\n",
    "\n",
    "        for frame in tqdm(frames, desc=f\"Augmenting Frames in Match {match_id}\", unit=\"frame\", leave=False):\n",
    "            frame_path = os.path.join(match_folder, frame)\n",
    "            image = Image.open(frame_path).convert(\"RGB\")\n",
    "            augmented_images = augment_image_multiple(image, num_augmentations=num_augmentations)\n",
    "\n",
    "            for i, augmented_image in enumerate(augmented_images):\n",
    "                augmented_path = os.path.join(\n",
    "                    match_folder, f\"{os.path.splitext(frame)[0]}_aug_{i+1}.jpg\"\n",
    "                )\n",
    "                augmented_image.save(augmented_path)\n",
    "\n",
    "    print(f\"Augmentation completed for {train_dir}, with {num_augmentations} augmentations per image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Matches: 100%|██████████| 63/63 [1:01:09<00:00, 58.24s/match]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation completed for ./data/masked_frame_split_by_match/train, with 10 augmentations per image.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# apply augmentation to the training data\n",
    "train_dir = './data/masked_frame_split_by_match/train'\n",
    "augment_train_data(train_dir, num_augmentations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
